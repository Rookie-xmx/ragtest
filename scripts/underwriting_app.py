from typing import List
import requests
import yaml
import time
import os
from FlagEmbedding import BGEM3FlagModel, FlagReranker
from pymilvus import (
    utility, FieldSchema, CollectionSchema, DataType,
    Collection, connections, db, AnnSearchRequest, RRFRanker
)
from collections import defaultdict
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate
from langchain_community.embeddings.huggingface import HuggingFaceInferenceAPIEmbeddings
import streamlit as st

# é…ç½®æ—¥å¿—è®°å½•å™¨
import logging
logger = logging.getLogger(__name__)

class SimpleOpenAIEmbeddings(HuggingFaceInferenceAPIEmbeddings):
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        batched_embeddings: List[List[float]] = []
        try:
            response = requests.post(
                "http://182.43.102.111:8090/v1/embeddings",
                headers=self._headers,
                json={
                    "input": texts,
                    "model": "Conan-embedding-v1",
                },
            )
            response = response.json()
            batched_embeddings.extend(r["embedding"] for r in response["data"])
        except Exception as e:
            logger.error('Exception: %s', e)
        return batched_embeddings

conan_embeddings = SimpleOpenAIEmbeddings(
    api_key="5F5D63CA-477A-4B65-9D8C-336D43CB1D53",
    model_name="Conan-embedding-v1",
    api_url="http://182.43.102.111:8090/v1/embeddings",
)

class RAGSystem:
    def __init__(self, config_path, prompt_config_path):
        self.load_configs(config_path, prompt_config_path)
        self.initialize_models()
        self.connect_milvus()
        self.initialize_llm()
        self.time_stats = {
            'search': 0.0,
            'rerank': 0.0,
            'llm': 0.0
        }
        self.last_retrieved_docs = [] # ç”¨äºå­˜å‚¨æœ€è¿‘ä¸€æ¬¡æ£€ç´¢åˆ°çš„æ–‡æ¡£

    def load_configs(self, config_path, prompt_config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        with open(prompt_config_path, 'r', encoding='utf-8') as f:
            self.prompt_config = yaml.safe_load(f)

    def initialize_models(self):
        embedding_args = self.config['embedding_model']
        print("Loading embedding model...") 
        self.bge_embedding_model = BGEM3FlagModel(
            embedding_args["root"] + embedding_args["base"], 
            use_fp16=False
        )
        print("Loading reranker model...") 
        self.reranker = FlagReranker(
            embedding_args["root"] + embedding_args["reranker"],
            use_fp16=True,
            normalize=True
        )
        print("Models loaded successfully.") 

    def connect_milvus(self):
        try:
            conn_args = self.config['milvus_conn_args']
            connections.connect(
                alias="default",
                host=conn_args['host'],
                port=conn_args['port'],
                user=conn_args['user'],
                password=conn_args['password']
            )
            db.using_database("test")
            self.examples_collection = Collection(name='examples')
            self.standard_collection = Collection(name='standard')
            print("Connected to Milvus successfully.")
        except Exception as e:
            raise ConnectionError(f"Milvus connection failed: {e}")

    def initialize_llm(self):
        llm_config = self.config['llm']
        # è¯»å– api_base é…ç½®
        api_base = llm_config.get("api_base", None)
        os.environ["OPENAI_API_BASE"] = api_base
        os.environ["OPENAI_API_KEY"] = self.config['llm']['api_key']

        self.llm = ChatOpenAI(
            model_name=self.config['llm']['model_name']
        )
    
    def _generate_prompt(self, query, references):
        return self.prompt_config["Underwriting_Prompt"].format(
            query=query,
            references=references
        )

    def _search_milvus(self, query, top_k=200): ##åˆ†ä¸º3æ­¥éª¤ï¼Œç¬¬ä¸€æ­¥æŒ‰ç…§companyname vectoræœç´¢ï¼Œç¬¬äºŒæ­¥æœç´¢examples collectionï¼Œç¬¬ä¸‰æ­¥æœç´¢standard collection
        start = time.time()
        
        ##query çš„ç¨ å¯†å‘é‡ï¼Œconanï¼Œdims len 1792
        query_dense_vector = conan_embeddings.embed_documents([query])

        ##query çš„ç¨€ç–å‘é‡ï¼Œbge-m3çš„embedding model
        bge_embeddings = self.bge_embedding_model.encode([query], 
                                                return_dense=False,
                                                return_sparse=True)

        bge_embeddings["sparse"] = [dict(bge_embeddings["lexical_weights"][0])]
        print(bge_embeddings["sparse"])

        ##å…ˆæŒ‰ç…§company_nameè¿›è¡Œæœç´¢ä¸¤ä¸ªcollectionï¼Œæ‰¾å‡ºtop2çš„company_nameï¼Œåˆ’å®šèŒƒå›´ã€‚
        # Step 1: è·å–ä¸¤ä¸ªcollectionçš„top2 company_name
        def get_top_companies(collection, vector_field,similarity_threshold=0.8):
            results = collection.search(
                data=[query_dense_vector[0]],
                anns_field=vector_field,
                param={"metric_type": "IP"},
                limit=100,
                output_fields=["company_name"]
            )

            #è¿‡æ»¤æ‰ç›¸ä¼¼åº¦ä½äºsimilarity_thresholdçš„ç»“æœ
            filtered_results = []
            for hit in results[0]:
                if hit.distance >= similarity_threshold:  # æ ¹æ®ç›¸ä¼¼åº¦åˆ†æ•°è¿‡æ»¤ç»“æœ
                    filtered_results.append(hit)
            unique_companies = set()  # ç”¨äºå­˜å‚¨ä¸åŒçš„å…¬å¸å

            for hit in filtered_results:
                unique_companies.add(hit.entity.company_name)
                if len(unique_companies) >= 2:  # å½“æ‰¾åˆ°ä¸¤ä¸ªä¸åŒçš„å…¬å¸åååœæ­¢
                    break
            return list(unique_companies)[:2]  # è¿”å›å‰ä¸¤ä¸ªä¸åŒçš„å…¬å¸å
        
        examples_companies = get_top_companies(self.examples_collection, "company_name_dense_vector")
        standard_companies = get_top_companies(self.standard_collection, "company_name_dense_vector")

        print(f"examples_companies: {examples_companies}")
        print(f"standard_companies: {standard_companies}")


        # Step 2: æ‰§è¡Œæ··åˆæœç´¢

        def hybrid_search(collection, dense_field, sparse_field, expr, fields,top_k=50,k_rrf=50):

            sparse_req = AnnSearchRequest(
                bge_embeddings["sparse"] ,
                sparse_field,
                {"metric_type": "IP"},
                limit=top_k,
                expr=expr
            )

            dense_req = AnnSearchRequest(
                query_dense_vector,
                dense_field,
                {"metric_type": "IP"},
                limit=top_k,
                expr=expr
            )


            return collection.hybrid_search(
            [sparse_req, dense_req],
            rerank=RRFRanker(k=k_rrf),
            limit=50,
            output_fields=fields
            ) 
        
        def format_companies(companies):
            return "['" + "', '".join(companies) + "']"
        # æœç´¢examples collection

        examples_results = hybrid_search(
            self.examples_collection,
            "true_example_dense_vector",
            "true_example_sparse_vector",
            f"company_name in {format_companies(examples_companies)}" if examples_companies else "",
            ["company_name", "product_name", "true_example_text"]
            )

        # æœç´¢standard collection
        standard_results = hybrid_search(
            collection=self.standard_collection,
            dense_field="standard_dense_vector",
            sparse_field="standard_sparse_vector",
            expr=f"company_name in {format_companies(standard_companies)}" if standard_companies else "",
            fields=["company_name", "underwriting_standard_text"],
            top_k=50,
            k_rrf=50
        )

        # åˆå¹¶ç»“æœ
        combined = []
        for hit in examples_results[0]:
            combined.append((
                hit.fields['true_example_text'],
                hit.distance,
                hit.id,
                'example'  # ç»“æœç±»å‹æ ‡è¯†
            ))
        
        for hit in standard_results[0]:
            combined.append((
                hit.fields['underwriting_standard_text'],
                hit.distance,
                hit.id,
                'standard'
            ))

        self.time_stats['search'] += time.time() - start
        return combined


    def _rerank_results(self, query, search_results, top_n=10):
        start = time.time()
        
        passages = [res[0] for res in search_results]
        pairs = [[query, passage] for passage in passages]
        
        scores = self.reranker.compute_score(pairs, normalize=False)
        combined = []
        for i in range(len(scores)):
            if scores[i] > -4:
                res = search_results[i]
                item = {
                    'text': passages[i],
                    'score': scores[i],
                    'type': res[-1],  # ç»“æœç±»å‹
                }
                combined.append(item)

        sorted_results = sorted(combined, key=lambda x: x['score'], reverse=True)
        self.time_stats['rerank'] += time.time() - start
        return sorted_results[:top_n]

    def _generate_response(self, prompt):
        start = time.time()
        
        template = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¿é™©é¢†åŸŸé¢„æ ¸ä¿ä¸“å®¶ï¼Œå–„äºä»å‚è€ƒèµ„æ–™ä¸­æ‰¾åˆ°ç›¸å…³ä¾æ®å¹¶æ ¹æ®è‡ªèº«ä¸“ä¸šçš„æ ¸ä¿é¢†åŸŸçŸ¥è¯†æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            ),
            HumanMessagePromptTemplate.from_template("{user_input}")
        ])
        messages = template.format_messages(user_input=prompt)
        response = self.llm.invoke(messages)
        
        self.time_stats['llm'] += time.time() - start
        return response.content

    def get_answer(self, query):
        try:
            # æ‰§è¡Œæœç´¢
            search_results = self._search_milvus(query)
            
            # é‡æ–°æ’åº
            reranked = self._rerank_results(query, search_results)
            self.last_retrieved_docs = reranked  # ä¿å­˜æ£€ç´¢åˆ°çš„æ–‡æ¡£

            print(f"rerankedçš„èµ„æ–™å¦‚ä¸‹:                      {reranked}")
            
            # æ„å»ºæç¤º
            references = "\n".join(
            [f"æ–‡æ¡£{i+1}ï¼š{('çœŸå®é¢„æ ¸ä¿æ¡ˆä¾‹' if res['type'] == 'example' else 'æ ¸ä¿æ ‡å‡†')}ï¼Œ{res['text'][0:800]}" for i, res in enumerate(reranked)]  )
            prompt = self._generate_prompt(query, references)

            print(prompt)
            
            # ç”Ÿæˆæœ€ç»ˆå“åº”
            return self._generate_response(prompt)
        except Exception as e:
            return f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"

    def get_time_stats(self):
        return self.time_stats.copy()

    def reset_time_stats(self):
        self.time_stats = {k: 0.0 for k in self.time_stats}

import streamlit as st
import time

# å‡è®¾RAGSystemç±»å’Œç›¸å…³ä¾èµ–å·²æ­£ç¡®å¯¼å…¥

@st.cache_resource
def load_rag_system():
    return RAGSystem(
        config_path='/data/myba/ragtest/config/ragtest.yaml',
        prompt_config_path='/data/myba/ragtest/config/prompt.yaml'
    )

def main():
    st.set_page_config(page_title="ä¿é™©æ ¸ä¿æ™ºèƒ½åŠ©æ‰‹", layout="wide")
    
    try:
        rag = load_rag_system()
    except Exception as e:
        st.error(f"ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
        st.stop()

    st.title("ğŸ“‘ ä¿é™©æ ¸ä¿æ™ºèƒ½åŠ©æ‰‹")
    
    with st.form("query_form"):
        query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š", placeholder="ä¾‹å¦‚ï¼šæˆ‘æœ‰å¿ƒè„ç—…å¯ä»¥ä¹°ä¸­æ„çš„å“ªäº›äº§å“")
        submitted = st.form_submit_button("å‘é€")
    
    if submitted and query:
        start_time = time.time()
        
        with st.spinner("æ­£åœ¨å…¨åŠ›ä¸ºæ‚¨è§£ç­”..."):
            try:
                answer = rag.get_answer(query)
                reranked_docs = rag.last_retrieved_docs
                process_time = time.time() - start_time
                
                col1, col2 = st.columns([1, 1], gap="large")
                
                with col1:
                    st.subheader("ğŸ” æ£€ç´¢åˆ°çš„ç›¸å…³èµ„æ–™")
                    if reranked_docs:
                        references = "\n\n".join(
                            [f"ğŸ“„ æ–‡æ¡£{i+1}ï¼ˆç±»å‹ï¼š{'æ¡ˆä¾‹' if doc['type'] == 'example' else 'æ ‡å‡†'}ï¼Œç›¸å…³åº¦ï¼š{doc['score']:.2f}ï¼‰:\n{doc['text'][:500]}..." 
                             for i, doc in enumerate(reranked_docs)]
                        )
                        st.text_area(label="å‚è€ƒèµ„æ–™", 
                                    value=references,
                                    height=400,
                                    label_visibility="collapsed")
                    else:
                        st.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
                
                with col2:
                    st.subheader("ğŸ’¡ æœ€ç»ˆç­”æ¡ˆ")
                    st.markdown(f"```\n{answer}\n```", unsafe_allow_html=True)
                    
                    st.markdown("---")
                    times = rag.get_time_stats()
                    total_time = times['search'] + times['rerank'] + times['llm']
                    
                    cols = st.columns(4)
                    cols[0].metric("æœç´¢è€—æ—¶", f"{times['search']:.2f}s")
                    cols[1].metric("é‡æ’åºè€—æ—¶", f"{times['rerank']:.2f}s")
                    cols[2].metric("å¤§æ¨¡å‹å“åº”", f"{times['llm']:.2f}s")
                    cols[3].metric("æ€»è€—æ—¶", f"{process_time:.2f}s")
                    
                rag.reset_time_stats()
                
            except Exception as e:
                st.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()

# if __name__ == '__main__':
#     # ä½¿ç”¨ç¤ºä¾‹
#     rag = RAGSystem(
#         config_path='/data/myba/ragtest/config/ragtest.yaml',
#         prompt_config_path='/data/myba/ragtest/config/prompt.yaml'
#     )

#     try:
#         while True:
#             query = input("\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥'exit'é€€å‡ºï¼‰: ")
#             if query.lower() == 'exit':
#                 break
            
#             start_total = time.time()
#             answer = rag.get_answer(query)
#             total_time = time.time() - start_total
            
#             print("\nç­”æ¡ˆï¼š")
#             print(answer)
            
#             # æ‰“å°æ—¶é—´ç»Ÿè®¡
#             times = rag.get_time_stats()
#             print("\næ—¶é—´ç»Ÿè®¡ï¼ˆç§’ï¼‰:")
#             print(f"æœç´¢è€—æ—¶: {times['search']:.2f}")
#             print(f"é‡æ’åºè€—æ—¶: {times['rerank']:.2f}")
#             print(f"å¤§æ¨¡å‹å“åº”è€—æ—¶: {times['llm']:.2f}")
#             print(f"æ€»è€—æ—¶: {total_time:.2f}")
            
#             rag.reset_time_stats()
            
#     except KeyboardInterrupt:
#         print("\nç¨‹åºå·²é€€å‡ºã€‚")